# Stage2: Instruction Finetuning (æŒ‡ä»¤å¾®è°ƒ)
# å†»ç»“ CLIPï¼Œè®­ç»ƒ Projection + Qwen3 å…¨å‚æ•°

direction: down

title: {
  label: "Stage2: æŒ‡ä»¤å¾®è°ƒè®­ç»ƒæµç¨‹"
  style: {
    font-size: 28
    bold: true
    underline: true
  }
}

# ============================================================
# æ•°æ®åŠ è½½
# ============================================================
data: {
  label: "æ•°æ®åŠ è½½"
  style: {
    fill: "#E3F2FD"
    stroke: "#1565C0"
    border-radius: 8
    font-size: 18
    bold: true
  }

  source: {
    label: "CogVLM-SFT-311K\næœ¬åœ°å›¾ç‰‡ + JSON æ ‡ç­¾"
    shape: cylinder
    style.fill: "#BBDEFB"
  }

  scan_single: {
    label: "æ‰«æå•è½®å¯¹è¯\nllava_instruction_single_conversation_formate\nimages/ + labels_zh/"
    shape: rectangle
    style.fill: "#E3F2FD"
  }

  scan_multi: {
    label: "æ‰«æå¤šè½®å¯¹è¯\nllava_instruction_multi_conversations_formate\nimages/ + labels_zh/"
    shape: rectangle
    style.fill: "#E3F2FD"
  }

  match: {
    label: "æŒ‰æ–‡ä»¶ååŒ¹é…\nJSON stem â†’ åŒå .jpg\nåˆå¹¶ä¸º all_samples"
    shape: rectangle
    style.fill: "#E3F2FD"
  }

  split: {
    label: "å›ºå®šç§å­åˆ’åˆ†\ntrain / eval\n(eval_ratio=0.02)"
    shape: rectangle
    style.fill: "#E3F2FD"
  }

  sample: {
    label: "æœ¬åœ°è¯»å–å›¾ç‰‡\nPIL Image.open()\n+ JSON conversations"
    shape: rectangle
    style.fill: "#E3F2FD"
  }

  source -> scan_single
  source -> scan_multi
  scan_single -> match
  scan_multi -> match
  match -> split -> sample
}

# ============================================================
# å›¾åƒé¢„å¤„ç†
# ============================================================
img_preprocess: {
  label: "å›¾åƒé¢„å¤„ç†"
  style: {
    fill: "#FFF3E0"
    stroke: "#E65100"
    border-radius: 8
    font-size: 18
    bold: true
  }

  resize: {
    label: "Resize(224, BICUBIC)"
    style.fill: "#FFE0B2"
  }
  crop: {
    label: "CenterCrop(224)"
    style.fill: "#FFE0B2"
  }
  tensor: {
    label: "ToTensor()"
    style.fill: "#FFE0B2"
  }
  norm: {
    label: "Normalize\n(CLIP mean/std)"
    style.fill: "#FFE0B2"
  }
  img_out: {
    label: "pixel_values\n[B, 3, 224, 224]"
    shape: parallelogram
    style.fill: "#FFCC80"
  }

  resize -> crop -> tensor -> norm -> img_out
}

# ============================================================
# æ–‡æœ¬é¢„å¤„ç†ï¼ˆå¤šè½®å¯¹è¯ï¼‰
# ============================================================
txt_preprocess: {
  label: "æ–‡æœ¬é¢„å¤„ç† (build_conversation_ids)"
  style: {
    fill: "#F3E5F5"
    stroke: "#6A1B9A"
    border-radius: 8
    font-size: 18
    bold: true
  }

  conversations: {
    label: "conversations\n[{role: user, content: Q1},\n {role: assistant, content: A1},\n {role: user, content: Q2},\n {role: assistant, content: A2}, ...]"
    shape: hexagon
    style.fill: "#E1BEE7"
  }

  incremental: {
    label: "é€è½®å¢é‡ç¼–ç \napply_chat_template\nåˆ°å½“å‰è½®ä¸ºæ­¢\n+ å·®å€¼å–æ–°å¢ token"
    style.fill: "#E1BEE7"
  }

  user_mask: {
    label: "User è½®\nâ†’ labels = -100 (æ©ç )"
    style.fill: "#E1BEE7"
  }

  asst_supervise: {
    label: "Assistant è½®\nâ†’ labels = token IDs (ç›‘ç£)"
    style.fill: "#E1BEE7"
  }

  truncate: {
    label: "æˆªæ–­åˆ° max_len=512\n(è¶…é•¿ä¸¢å¼ƒå°¾éƒ¨è½®æ¬¡)"
    style.fill: "#E1BEE7"
  }

  ids_out: {
    label: "input_ids [B, T]\nlabels [B, T]\n(T â‰¤ 512)"
    shape: parallelogram
    style.fill: "#CE93D8"
  }

  conversations -> incremental
  incremental -> user_mask
  incremental -> asst_supervise
  user_mask -> truncate
  asst_supervise -> truncate
  truncate -> ids_out
}

# ============================================================
# Collate & DataLoader
# ============================================================
collate: {
  label: "Collate Function\nå †å å›¾åƒ + å¡«å……åºåˆ—åˆ°ç›¸åŒé•¿åº¦ (pad_sequences)"
  shape: rectangle
  style: {
    fill: "#F1F8E9"
    stroke: "#33691E"
    font-size: 16
    border-radius: 8
  }
}

# ============================================================
# æ¨¡å‹åŠ è½½ï¼ˆStage 1 æƒé‡ + å†»ç»“ç­–ç•¥ï¼‰
# ============================================================
model_init: {
  label: "æ¨¡å‹åˆå§‹åŒ–"
  style: {
    fill: "#E0F2F1"
    stroke: "#004D40"
    border-radius: 8
    font-size: 18
    bold: true
  }

  load_base: {
    label: "åŠ è½½åŸºç¡€æ¨¡å‹\nCLIP ViT-B/16 + Qwen3-0.6B\n+ éšæœºåˆå§‹åŒ– Projection"
    shape: rectangle
    style.fill: "#B2DFDB"
  }

  load_proj: {
    label: "åŠ è½½ Stage 1 æƒé‡\nstage1_projection.pt\nâ†’ projection.load_state_dict()"
    shape: cylinder
    style: {
      fill: "#80CBC4"
      stroke: "#004D40"
      font-size: 14
      bold: true
    }
  }

  freeze_clip: {
    label: "å†»ç»“ç­–ç•¥\nCLIP: requires_grad=False â„ï¸\nProjection: å¯è®­ç»ƒ ğŸ”¥\nQwen3 LLM: å¯è®­ç»ƒ ğŸ”¥"
    shape: rectangle
    style: {
      fill: "#B2DFDB"
      stroke: "#004D40"
      stroke-width: 2
    }
  }

  grad_ckpt: {
    label: "gradient_checkpointing_enable()\nä¸ä¿å­˜ä¸­é—´æ¿€æ´»å€¼ï¼Œåå‘æ—¶é‡è®¡ç®—\nä»¥è®¡ç®—é‡æ¢æ˜¾å­˜"
    shape: rectangle
    style.fill: "#B2DFDB"
  }

  load_base -> load_proj -> freeze_clip -> grad_ckpt
}

# ============================================================
# æ¨¡å‹å‰å‘ä¼ æ’­
# ============================================================
forward: {
  label: "æ¨¡å‹å‰å‘ä¼ æ’­"
  style: {
    fill: "#E8F5E9"
    stroke: "#1B5E20"
    border-radius: 8
    font-size: 18
    bold: true
  }

  clip: {
    label: "CLIPVisionTower\n(å†»ç»“ â„ï¸)\nChinese-CLIP ViT-B/16"
    shape: rectangle
    style: {
      fill: "#C8E6C9"
      stroke: "#2E7D32"
      stroke-dash: 5
    }
  }

  clip_out: {
    label: "è§†è§‰ç‰¹å¾\n[B, 197, 768]"
    shape: parallelogram
    style.fill: "#A5D6A7"
  }

  projection: {
    label: "MultimodalProjection\n(å¯è®­ç»ƒ ğŸ”¥, Stage 1 é¢„è®­ç»ƒæƒé‡)\nLinear(768â†’1024) â†’ GELU â†’ Linear(1024â†’1024)"
    shape: rectangle
    style: {
      fill: "#FF8A65"
      stroke: "#BF360C"
      stroke-width: 3
    }
  }

  proj_out: {
    label: "visual_embeds\n[B, 197, 1024]"
    shape: parallelogram
    style.fill: "#A5D6A7"
  }

  embed_tokens: {
    label: "llm.embed_tokens\n(Qwen3, å¯è®­ç»ƒ ğŸ”¥)"
    shape: rectangle
    style: {
      fill: "#FF8A65"
      stroke: "#BF360C"
      stroke-width: 2
    }
  }

  text_embeds: {
    label: "text_embeds\n[B, T, 1024]"
    shape: parallelogram
    style.fill: "#A5D6A7"
  }

  concat_embeds: {
    label: "Concat Embeds\ntorch.cat([visual_embeds, text_embeds], dim=1)"
    shape: diamond
    style: {
      fill: "#DCEDC8"
      stroke: "#33691E"
    }
  }

  combined_embeds: {
    label: "combined_embeds\n[B, 197+T, 1024]"
    shape: parallelogram
    style.fill: "#A5D6A7"
  }

  # ---- æ„é€  combined_labels ----
  ignore_labels: {
    label: "æ„é€  ignore_labels\ntorch.full((B, 197), -100)\nè§†è§‰ token ä½ç½®ä¸è®¡ç®— loss"
    shape: rectangle
    style: {
      fill: "#FFECB3"
      stroke: "#FF6F00"
      stroke-width: 2
    }
  }

  concat_labels: {
    label: "Concat Labels\ntorch.cat([ignore_labels, labels], dim=1)"
    shape: diamond
    style: {
      fill: "#DCEDC8"
      stroke: "#33691E"
    }
  }

  combined_labels: {
    label: "combined_labels\n[B, 197+T]\n(å‰ 197 ä½ = -100,\nå T ä½ = user:-100 / asst:token_ids)"
    shape: parallelogram
    style.fill: "#A5D6A7"
  }

  llm: {
    label: "Qwen3-0.6B\n(å¯è®­ç»ƒ ğŸ”¥, gradient_checkpointing)\nFlash Attention 2, bf16"
    shape: rectangle
    style: {
      fill: "#FF8A65"
      stroke: "#BF360C"
      stroke-width: 3
    }
  }

  loss: {
    label: "CrossEntropy Loss\n(ä»…è®¡ç®— Assistant å›å¤éƒ¨åˆ†)"
    shape: parallelogram
    style: {
      fill: "#FFCDD2"
      stroke: "#B71C1C"
      font-size: 16
      bold: true
    }
  }

  clip -> clip_out -> projection -> proj_out -> concat_embeds
  embed_tokens -> text_embeds -> concat_embeds
  concat_embeds -> combined_embeds

  proj_out -> ignore_labels: "num_visual_tokens = 197" {
    style: {
      stroke: "#FF6F00"
      stroke-dash: 3
    }
  }
  ignore_labels -> concat_labels
  concat_labels -> combined_labels

  combined_embeds -> llm
  combined_labels -> llm: "labels" {
    style: {
      stroke: "#FF6F00"
      stroke-width: 2
    }
  }
  llm -> loss
}

# ============================================================
# è®­ç»ƒå¾ªç¯
# ============================================================
training: {
  label: "è®­ç»ƒå¾ªç¯"
  style: {
    fill: "#FFF9C4"
    stroke: "#F57F17"
    border-radius: 8
    font-size: 18
    bold: true
  }

  autocast: {
    label: "torch.amp.autocast(bf16)\næ··åˆç²¾åº¦å‰å‘ä¼ æ’­"
    style.fill: "#FFF59D"
  }

  backward: {
    label: "loss.backward()\næ¢¯åº¦æµå‘ Projection + LLM"
    style.fill: "#FFF59D"
  }

  grad_clip: {
    label: "clip_grad_norm_\n(max_norm=1.0)\né˜²æ­¢æ¢¯åº¦çˆ†ç‚¸"
    style.fill: "#FFF59D"
  }

  optimizer: {
    label: "AdamW.step()\n(lr=2e-5, æ›´æ–° Projection + LLM)"
    style.fill: "#FFF59D"
  }

  scheduler: {
    label: "CosineScheduler.step()\n(warmup 3%)"
    style.fill: "#FFF59D"
  }

  zero_grad: {
    label: "optimizer.zero_grad()"
    style.fill: "#FFF59D"
  }

  autocast -> backward -> grad_clip -> optimizer -> scheduler -> zero_grad
}

# ============================================================
# æ—¥å¿—ä¸è¯„ä¼°
# ============================================================
logging: {
  label: "æ—¥å¿— & è¯„ä¼° & ä¿å­˜"
  style: {
    fill: "#FCE4EC"
    stroke: "#880E4F"
    border-radius: 8
    font-size: 18
    bold: true
  }

  log_step: {
    label: "æ¯ 10 æ­¥\næ‰“å° loss / perplexity / lr"
    shape: rectangle
    style.fill: "#F8BBD0"
  }

  eval_step: {
    label: "æ¯ 500 æ­¥\nåœ¨ eval set ä¸Šè¯„ä¼°\n(200 samples)"
    shape: rectangle
    style.fill: "#F8BBD0"
  }

  save_step: {
    label: "æ¯ 2000 æ­¥\nä¿å­˜ checkpoint\nstage2_llava_step{N}.pt\n(å®Œæ•´æ¨¡å‹æƒé‡)"
    shape: rectangle
    style.fill: "#F8BBD0"
  }

  tensorboard: {
    label: "TensorBoard\ntrain/eval loss\nperplexity, lr"
    shape: cylinder
    style.fill: "#F48FB1"
  }

  log_step -> tensorboard
  eval_step -> tensorboard
}

# ============================================================
# æœ€ç»ˆè¾“å‡º
# ============================================================
final: {
  label: "è®­ç»ƒç»“æŸ"
  style: {
    fill: "#E0F7FA"
    stroke: "#006064"
    border-radius: 8
    font-size: 18
    bold: true
  }

  final_eval: {
    label: "å®Œæ•´ eval set è¯„ä¼°\n(å…¨é‡ï¼Œmax_batches=0)"
    style.fill: "#B2EBF2"
  }

  save_final: {
    label: "ä¿å­˜æœ€ç»ˆå®Œæ•´æ¨¡å‹æƒé‡\nstage2_llava.pt\n(CLIP + Projection + LLM)"
    shape: cylinder
    style: {
      fill: "#80DEEA"
      stroke: "#006064"
      font-size: 16
      bold: true
    }
  }

  final_eval -> save_final
}

# ============================================================
# Stage 1 vs Stage 2 å¯¹æ¯”è¯´æ˜
# ============================================================
comparison: {
  label: "Stage 1 â†’ Stage 2 å…³é”®å˜åŒ–"
  style: {
    fill: "#FBE9E7"
    stroke: "#BF360C"
    border-radius: 8
    font-size: 16
    bold: true
  }

  diff: {
    label: ||md
      | ç»´åº¦ | Stage 1 | Stage 2 |
      |------|---------|---------|
      | ç›®æ ‡ | è§†è§‰-è¯­è¨€å¯¹é½ | æŒ‡ä»¤å¾®è°ƒ |
      | æ•°æ® | SA1B å›¾æ–‡æè¿° | CogVLM-SFT å¤šè½®å¯¹è¯ |
      | å¯è®­ç»ƒ | ä»… Projection | Projection + LLM |
      | å­¦ä¹ ç‡ | 2e-3 | 2e-5 |
      | max_len | 128 | 512 |
      | æ¢¯åº¦è£å‰ª | æ—  | max_norm=1.0 |
      | ä¿å­˜å†…å®¹ | projection.pt | å®Œæ•´æ¨¡å‹ state_dict |
    ||
    style: {
      fill: "#FFCCBC"
      font-size: 13
    }
  }
}

# ============================================================
# ä¸»æµç¨‹è¿æ¥
# ============================================================
data.sample -> img_preprocess.resize: "PIL Image" {
  style.stroke: "#E65100"
}
data.sample -> txt_preprocess.conversations: "conversations" {
  style.stroke: "#6A1B9A"
}

img_preprocess.img_out -> collate: "pixel_values" {
  style.stroke: "#E65100"
}
txt_preprocess.ids_out -> collate: "input_ids + labels" {
  style.stroke: "#6A1B9A"
}

model_init.grad_ckpt -> forward.clip: "æ¨¡å‹å°±ç»ª" {
  style: {
    stroke: "#004D40"
    stroke-width: 2
  }
}

collate -> forward.clip: "pixel_values" {
  style.stroke: "#E65100"
}
collate -> forward.embed_tokens: "input_ids" {
  style.stroke: "#6A1B9A"
}
collate -> forward.concat_labels: "labels [B, T]" {
  style.stroke: "#FF6F00"
}

forward.loss -> training.autocast: "loss" {
  style: {
    stroke: "#B71C1C"
    stroke-width: 2
  }
}

training.zero_grad -> forward.clip: "ä¸‹ä¸€ä¸ª batch" {
  style: {
    stroke: "#F57F17"
    stroke-dash: 5
  }
}

training.zero_grad -> logging.log_step: "å®šæœŸ" {
  style: {
    stroke: "#880E4F"
    stroke-dash: 5
  }
}
training.zero_grad -> logging.eval_step: "å®šæœŸ" {
  style: {
    stroke: "#880E4F"
    stroke-dash: 5
  }
}
training.zero_grad -> logging.save_step: "å®šæœŸ" {
  style: {
    stroke: "#880E4F"
    stroke-dash: 5
  }
}

logging.save_step -> final.final_eval: "è®­ç»ƒå®Œæˆå" {
  style: {
    stroke: "#006064"
    stroke-width: 2
  }
}
